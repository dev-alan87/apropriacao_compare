{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS AND INSTALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "# local do arquivo\n",
    "file_path = 'RHPP05LA.PDF'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcao de dados\n",
    "SUBSTITUICOES = {\n",
    "    \"1/12 FERIAS\"           : \"ferias\", \n",
    "    \"1/12 ferias\"           : \"ferias\", \n",
    "    \"1/12 DE 1 /3 FERIAS\"   : \"13_ferias\", \n",
    "    \"1 /3 ferias\"           : \"13_ferias\", \n",
    "    \"1 /3 FERIAS\"           : \"13_ferias\", \n",
    "    \"1/12 DE 13_ferias\"     : \"13_ferias\", \n",
    "    \"TOTAL ferias\"          : \"total_ferias\", \n",
    "    \"TOTAL FERIAS\"          : \"total_ferias\", \n",
    "    \"1/12 13 SAL ARIO\"      : \"13_salario\", \n",
    "    \"13 SAL ARIO\"           : \"13_salario\", \n",
    "    \"T O T A L\"             : \"total\", \n",
    "    \"PROVISIONAMENTO\"       : \"apropriacao\", \n",
    "    \"INSS  20,00%\"          : \"inss\", \n",
    "    \"SP-PREVCOM\"            : \"spprevcom\", \n",
    "    \"AC TRAB  \"             : \"ac_trab-\", \n",
    "    \"FGTS 8%\"               : \"fgts\", \n",
    "    \"TOTAL DE ENCARGOS\"     : \"total_encargos\", \n",
    "    \".\"                     : \"\", \n",
    "    \",\"                     : \".\", \n",
    "    \"SPPREV\"                : \"spprev\", \n",
    "    \"FERIAS\"                : \"ferias\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcao que divide uma lista em duas listas\n",
    "# de acordo com a palavra enviada e os pads definidos\n",
    "def split_tables(\n",
    "        tb: list, \n",
    "        split_word:str=\"\", \n",
    "        pad_top_tb1:int=0,\n",
    "        pad_bottom_tb1:int=0,\n",
    "        pad_top_tb2:int=0,\n",
    "        pad_bottom_tb2:int=0\n",
    "        ):\n",
    "    \n",
    "    for i in range(len(tb)):\n",
    "        if split_word in tb[i]:\n",
    "            tb1 = tb[pad_top_tb1:i+pad_bottom_tb1]\n",
    "            tb2 = tb[i+pad_top_tb2:] if pad_bottom_tb2==0 else tb[i+pad_top_tb2:pad_bottom_tb2] \n",
    "    return tb1, tb2\n",
    "\n",
    "# funcao que normatiza palavras-campos das tabelas\n",
    "def correct_words(tb: list):\n",
    "    for i in range(len(tb)):\n",
    "        for search, correct in SUBSTITUICOES.items():\n",
    "            tb[i] = tb[i].replace(search, correct.lower())\n",
    "    return tb\n",
    "\n",
    "# funcao que corrige os dados numericos quebrados por espaco\n",
    "def data_processing(datas:list):\n",
    "    for data in datas:\n",
    "        i = 0\n",
    "        while i < len(data) - 1:\n",
    "            if \".\" not in data[i]:\n",
    "                data[i] += data[i+1]\n",
    "                del data[i+1]\n",
    "            else:\n",
    "                i += 1\n",
    "    return datas\n",
    "\n",
    "# funcao que extrai cabecalho, itens e dados da lista \n",
    "# formato tabela: \n",
    "## linha    0:  cabecalhos\n",
    "## coluna   0:  itens\n",
    "## coluna 1-5:  dados\n",
    "def extract_tables(tb:list):\n",
    "    tb = correct_words(tb)\n",
    "\n",
    "    headers = tb[0].split()\n",
    "\n",
    "    datas = tb[1:]\n",
    "    for i in range(len(datas)):\n",
    "        datas[i] = datas[i].split()\n",
    "    \n",
    "    items = [data[0] for data in datas]\n",
    "\n",
    "    datas = [data[1:] for data in datas]\n",
    "    datas = data_processing(datas)\n",
    "\n",
    "    return headers, items, datas\n",
    "\n",
    "def cast_table_to_df(tb:list) -> pd.DataFrame:\n",
    "    headers, items, datas = extract_tables(tb)\n",
    "\n",
    "    dictionary = {' ': items}\n",
    "\n",
    "    for header, collumn in zip(headers, zip(*datas)):\n",
    "        dictionary[header] = float(collumn) if isinstance(collumn, float) else collumn\n",
    "\n",
    "    return pd.DataFrame(dictionary)\n",
    "\n",
    "\n",
    "\n",
    "# funcao que coloca a tabela em formato de tupla\n",
    "def cast_table_to_tuple(tb:list) -> tuple:\n",
    "    headers, items, datas = extract_tables(tb)\n",
    "    \n",
    "    tup = {}\n",
    "    \n",
    "    for type, data in zip(items, datas):\n",
    "        tup[type] = {}\n",
    "        for header, value in zip(headers, data):\n",
    "            tup[type][header] = float(value)\n",
    "\n",
    "    return tup   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXECUÇÃO PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m tb_aut_apropriado   \u001b[38;5;241m=\u001b[39m cast_table_to_df(tb_aut_apropriado)\n\u001b[1;32m     35\u001b[0m tb_aut_realizado    \u001b[38;5;241m=\u001b[39m cast_table_to_df(tb_aut_realizado)\n\u001b[0;32m---> 37\u001b[0m display(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m------------\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43munidade\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcodigo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39munidade[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnome\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApropriado\u001b[39m\u001b[38;5;124m\"\u001b[39m, tb_clt_apropriado, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealizado\u001b[39m\u001b[38;5;124m\"\u001b[39m, tb_clt_realizado, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUTÁRQUICO\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApropriado\u001b[39m\u001b[38;5;124m\"\u001b[39m, tb_aut_apropriado, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRealizado\u001b[39m\u001b[38;5;124m\"\u001b[39m, tb_aut_realizado)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "unidades = {}\n",
    "\n",
    "# ler pdf\n",
    "with open(file_path, 'rb') as pdf_file:\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    pages = pdf_reader.pages\n",
    "\n",
    "    # para cada page indexada com um number_page\n",
    "    # extrair texto e colocar em lines (retirando as em branco)\n",
    "    for number_page, page in enumerate(pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        lines = text.split(\"\\n\")\n",
    "        lines = [line for line in lines if not line.isspace()]\n",
    "\n",
    "        # extrai dados da unidade\n",
    "        unidade = {}\n",
    "        unidade['codigo'] = int(lines[3].strip().split(\" - \")[0].replace(\" \", \"\"))\n",
    "        unidade['nome'] = lines[3].strip().split(\" - \")[1]\n",
    "\n",
    "        # se a pagina for impar, os dados sao referentes apropriado e realizado da unidade\n",
    "        # se a pagina for par, os dados sao referentes aos totais da unidade\n",
    "        if(number_page %2 == 1):\n",
    "\n",
    "            # extrai tabela CLT e Autarquico\n",
    "            tb_clt, tb_aut = split_tables(lines, \"A U T A R Q U I C O\", 7, -1, 2, -1)\n",
    "\n",
    "            # extrai apropriado e realizado da tabela\n",
    "            tb_clt_apropriado, tb_clt_realizado = split_tables(tb_clt, \"R E V E R S A O\", 1, 0, 1)\n",
    "            tb_aut_apropriado, tb_aut_realizado = split_tables(tb_aut, \"R E V E R S A O\", 1, 0, 1)\n",
    "\n",
    "            # gera dataframe para as tabelas\n",
    "            tb_clt_apropriado   = cast_table_to_df(tb_clt_apropriado)\n",
    "            tb_clt_realizado    = cast_table_to_df(tb_clt_realizado)\n",
    "            tb_aut_apropriado   = cast_table_to_df(tb_aut_apropriado)\n",
    "            tb_aut_realizado    = cast_table_to_df(tb_aut_realizado)\n",
    "\n",
    "            display(str(unidade[\"codigo\"])+\" - \"+unidade[\"nome\"], \"CLT\", \"Apropriado\", tb_clt_apropriado, \"Realizado\", tb_clt_realizado, \"AUTÁRQUICO\", \"Apropriado\", tb_aut_apropriado, \"Realizado\", tb_aut_realizado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
